{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielx1611/ComputerVisionAssignments/blob/main/EstimateCameraPose/EstimateCameraPose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimate the Pose of Cameras Using Planar Objects"
      ],
      "metadata": {
        "id": "NLVX1HNhzDTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependency installations"
      ],
      "metadata": {
        "id": "MgBlKgwbzTx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogOUN7m-eI3c",
        "outputId": "f45da396-4b17-4f4e-c4d9-8f184afeae7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pytransform3d in /usr/local/lib/python3.12/dist-packages (3.14.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytransform3d) (1.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from pytransform3d) (5.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install gradio numpy opencv-python matplotlib pytransform3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmAlCSvamr93",
        "outputId": "2615a9d6-e571-4e30-8a94-d01ddfe3e744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in collab\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import time\n",
        "import gradio\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pytransform3d.camera as pc\n",
        "import pytransform3d.transformations as pt\n",
        "import io\n",
        "from cvxopt import matrix, printing\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "def cv2_imshow(img):\n",
        "    cv.imshow(\"img\", img)\n",
        "    time.sleep(1)\n",
        "    cv.destroyAllWindows()\n",
        "\n",
        "CONTENT_DIR = Path(\".\")\n",
        "\n",
        "try:\n",
        "    import google.colab.patches as patches\n",
        "    print(\"in collab\")\n",
        "    cv2_imshow = patches.cv2_imshow\n",
        "    CONTENT_DIR = Path(\"/content\")\n",
        "\n",
        "    if not Path(\"ComputerVisionAssignments\").exists():\n",
        "      !git clone https://github.com/danielx1611/ComputerVisionAssignments.git\n",
        "\n",
        "    # Move test files to the Colab local directory (i.e., /content/)\n",
        "    if not Path(\"chess_jpg\").exists():\n",
        "      !mkdir chess_jpg\n",
        "    !cp -r ComputerVisionAssignments/PinholeCameraModel/chess_jpg/* ./chess_jpg\n",
        "\n",
        "    if not Path(\"planar_jpg\").exists():\n",
        "      !mkdir planar_jpg\n",
        "    !cp -r ComputerVisionAssignments/EstimateCameraPose/planar_jpg/* ./planar_jpg\n",
        "    !cp ComputerVisionAssignments/EstimateCameraPose/ref_points.json .\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# using this for now\n",
        "CONTENT_DIR = Path(\".\")\n",
        "for img_path in CONTENT_DIR.glob(\"*.jpg\"):\n",
        "  print(img_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Camera Calibration"
      ],
      "metadata": {
        "id": "wP9yRolCzXzx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGG_Yp2C4nEC"
      },
      "outputs": [],
      "source": [
        "calibration_images_dir = CONTENT_DIR / \"chess_jpg\"\n",
        "planar_images_dir = CONTENT_DIR / \"planar_jpg\"\n",
        "output_dir = CONTENT_DIR / \"output\"\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "class Calibration:\n",
        "    @staticmethod\n",
        "    def run():\n",
        "        # termination criteria\n",
        "        criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "        # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
        "        objp = np.zeros((6*9,3), np.float32)\n",
        "        objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
        "\n",
        "        # Arrays to store object points and image points from all the images.\n",
        "        objpoints = [] # 3d point in real world space\n",
        "        imgpoints = [] # 2d points in image plane.\n",
        "\n",
        "        # images = glob.glob(calibration_images_dir + \"/\" + \"*.jpg\")\n",
        "\n",
        "        images = list(calibration_images_dir.glob(\"*.jpg\"))\n",
        "        gray = None\n",
        "        rgb_images = []\n",
        "        for fname in images:\n",
        "            img = cv.imread(fname)\n",
        "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Find the chess board corners\n",
        "            ret, corners = cv.findChessboardCorners(gray, (9,6), None)\n",
        "\n",
        "            # If found, add object points, image points (after refining them)\n",
        "            if ret == True:\n",
        "                objpoints.append(objp)\n",
        "\n",
        "                corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
        "                imgpoints.append(corners2)\n",
        "\n",
        "                # Draw and display the corners\n",
        "                cv.drawChessboardCorners(img, (9,6), corners2, ret)\n",
        "\n",
        "                # store rgb image\n",
        "                color_fixed = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "                rgb_images.append(color_fixed)\n",
        "\n",
        "        ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
        "        h, w = img.shape[:2]\n",
        "        calibration_data = {\n",
        "            \"K\": mtx.tolist(),  # Intrinsic matrix\n",
        "            \"D\": dist.tolist(),  # Distortion coefficients\n",
        "            \"R\": [\n",
        "                cv.Rodrigues(r)[0].tolist() for r in rvecs\n",
        "            ],  # Convert rvec to rotation matrix\n",
        "            \"t\": [t.tolist() for t in tvecs],  # Translation vectors\n",
        "            \"width\": w,\n",
        "            \"height\": h,\n",
        "        }\n",
        "\n",
        "        image_grid(rgb_images[:4], rows=2, cols=2, rgb=True, show_axes=False)\n",
        "\n",
        "        with open(\"calibration.json\", \"w\") as f:\n",
        "                json.dump(calibration_data, f, indent=2)\n",
        "        return \"Calibration successful\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "Vr9SolIazhgf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW_hwRb1NyMj"
      },
      "outputs": [],
      "source": [
        "def image_grid(\n",
        "    images,\n",
        "    rows=None,\n",
        "    cols=None,\n",
        "    fill: bool = True,\n",
        "    show_axes: bool = False,\n",
        "    rgb: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    A util function for plotting a grid of images.\n",
        "\n",
        "    Args:\n",
        "        images: (N, H, W, 4) array of RGBA images\n",
        "        rows: number of rows in the grid\n",
        "        cols: number of columns in the grid\n",
        "        fill: boolean indicating if the space between images should be filled\n",
        "        show_axes: boolean indicating if the axes of the plots should be visible\n",
        "        rgb: boolean, If True, only RGB channels are plotted.\n",
        "            If False, only the alpha channel is plotted.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if (rows is None) != (cols is None):\n",
        "        raise ValueError(\"Specify either both rows and cols or neither.\")\n",
        "\n",
        "    if rows is None:\n",
        "        rows = len(images)\n",
        "        cols = 1\n",
        "\n",
        "    gridspec_kw = {\"wspace\": 0.0, \"hspace\": 0.0} if fill else {}\n",
        "    fig, axarr = plt.subplots(rows, cols, gridspec_kw=gridspec_kw, figsize=(15, 9))\n",
        "    bleed = 0\n",
        "    fig.subplots_adjust(left=bleed, bottom=bleed, right=(1 - bleed), top=(1 - bleed))\n",
        "\n",
        "    for ax, im in zip(axarr.ravel(), images):\n",
        "        if rgb:\n",
        "            # only render RGB channels\n",
        "            ax.imshow(im[..., :3])\n",
        "        else:\n",
        "            # only render Alpha channel\n",
        "            ax.imshow(im[..., 3])\n",
        "        if not show_axes:\n",
        "            ax.set_axis_off()\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QO455oo9KrE"
      },
      "outputs": [],
      "source": [
        "class Utils:\n",
        "    @staticmethod\n",
        "    def project_points(W: np.ndarray,\n",
        "                       Lambda: np.ndarray,\n",
        "                       Rt: np.ndarray) -> np.ndarray:\n",
        "        \"\"\" Helper function to project 3D points to 2D image plane\"\"\"\n",
        "\n",
        "        # Convert points to homogeneous coordinates\n",
        "        W_tilde = np.vstack((W, np.ones((1, W.shape[1]))))\n",
        "\n",
        "        print(f\"W_tilde = \\n{W_tilde}\\n\")\n",
        "\n",
        "        # Calculate perspective projection in homogeneous coordinates\n",
        "        X_tilde = Lambda @ Rt @ W_tilde\n",
        "\n",
        "        print(f\"X_tilde =  \\n{X_tilde}\\n\")\n",
        "\n",
        "        # Apply perspective division to convert coordinates from homogeneous to Cartesian\n",
        "        X_tilde /= X_tilde[2,:]\n",
        "        # Convert coordinates from homogeneous to Cartesian\n",
        "        X = X_tilde[0:2,:]\n",
        "\n",
        "        return X\n",
        "\n",
        "    @staticmethod\n",
        "    def draw_coordinate_frame(image_points, img):\n",
        "        #x0, y0 = int(image_points[0,0]), int(image_points[1,0])\n",
        "        x0, y0 = image_points[:,0].astype(int)\n",
        "        #print(str(type(x0)) + \" \" + str(type(y0)))\n",
        "        cv.circle(img, (x0, y0), 48, (0, 0, 0), -1)\n",
        "\n",
        "        #x1, y1 = int(image_points[0,1]), int(image_points[1,1])\n",
        "        x1, y1 = image_points[:,1].astype(int)\n",
        "        #print(str(type(x1)) + \" \" + str(type(y1)))\n",
        "        img = cv.arrowedLine(img, (x0, y0), (x1, y1), (255, 0, 0), 16)\n",
        "\n",
        "        #x2, y2 = int(image_points[0,2]), int(image_points[1,2])\n",
        "        x2, y2 = image_points[:,2].astype(int)\n",
        "        #print(str(type(x2)) + \" \" + str(type(y2)))\n",
        "        img = cv.arrowedLine(img, (x0, y0), (x2, y2), (0, 255, 0), 16)\n",
        "\n",
        "        #x3, y3 = int(image_points[0,3]), int(image_points[1,3])\n",
        "        x3, y3 = image_points[:,3].astype(int)\n",
        "        #print(str(type(x3)) + \" \" + str(type(y3)))\n",
        "        img = cv.arrowedLine(img, (x0, y0), (x3, y3), (0, 0, 255), 16)\n",
        "\n",
        "        plt.imshow(img)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_Lambda(phi_x, phi_y, skew, delta_x, delta_y):\n",
        "        \"\"\" Build the intrinsic camera matrix Lambda \"\"\"\n",
        "        Lambda = np.array([[phi_x,  skew, delta_x],\n",
        "                           [    0, phi_y, delta_y],\n",
        "                           [    0,     0,       1]])\n",
        "        return Lambda\n",
        "\n",
        "    @staticmethod\n",
        "    def json_read(filename):\n",
        "        # Parses the json file\n",
        "        try:\n",
        "            with open(os.path.abspath(filename)) as f:\n",
        "                data = json.load(f)\n",
        "            return data\n",
        "        except:\n",
        "            raise ValueError(\"Unable to read JSON {}\".format(filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Camera Pose and Position Extraction"
      ],
      "metadata": {
        "id": "MvJ8woUKzkg2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0fYVJu2F_1g"
      },
      "outputs": [],
      "source": [
        "class Pose:\n",
        "  def run_get_homography():\n",
        "    # Make a list of input images of the rectangles.\n",
        "    raw_images = [(img_path, cv.imread(img_path), json.loads(open(json_path, \"r\").read())) for img_path, json_path in zip(\n",
        "        sorted(planar_images_dir.glob(\"*.jpg\")),\n",
        "        sorted(planar_images_dir.glob(\"*.json\"))\n",
        "    )]\n",
        "\n",
        "    # Convert all images in the list from BGR to RGB to show correct colors.\n",
        "    raw_images = [(path, cv.cvtColor(img, cv.COLOR_BGR2RGB), json) for path, img, json in raw_images]\n",
        "\n",
        "    ########################################################################\n",
        "    # In this example, the images are already scaled down and corrected\n",
        "    # for lens distortion. When using images from your own camera, you\n",
        "    # might need to scale them down and also correct for lens distortion.\n",
        "    # To do that, uncomment the following steps and adapt the names of variables.\n",
        "    ########################################################################\n",
        "\n",
        "    # Undistort the images using the refined camera matrix (removes lens distortion)\n",
        "    #undistorted_images = [cv.undistort(img, camera_matrix, distortion_coefficients, None, refined_camera_matrix) for img in scaled_images]\n",
        "\n",
        "    # Display a sample of images\n",
        "    before = image_grid(map(lambda i: i[1], raw_images[:4]), rows=2, cols=2, rgb=True, show_axes=False)\n",
        "\n",
        "    # Object points in world coordinates.\n",
        "    # The world coordinate frame and the object's coordinate frame are the same.\n",
        "    ref_points = json.loads(open(\"ref_points.json\", \"r\").read())\n",
        "\n",
        "    calibration = json.loads(open(\"calibration.json\", \"r\").read())\n",
        "\n",
        "    mtx = np.array(calibration[\"K\"])\n",
        "    dist = np.array(calibration[\"D\"])\n",
        "    w = calibration[\"width\"]\n",
        "    h = calibration[\"height\"]\n",
        "\n",
        "    # new_mtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
        "    # raw_images = [cv.undistort(img, mtx, dist, None, new_mtx) for img in raw_images]\n",
        "\n",
        "    # x,y,w,h = roi\n",
        "    # raw_images = [img[y:y+h, x:x+w] for img in raw_images]\n",
        "\n",
        "    labelled_points = []\n",
        "\n",
        "    for path, image, points in raw_images:\n",
        "        for j in range(0,4):\n",
        "            # Draw circles at the image features\n",
        "            image = cv.circle(image,\n",
        "                              (np.int32(points[j][0]),np.int32(points[j][1])),\n",
        "                              32, (255,0,0), -1)\n",
        "\n",
        "            # Draw text labels at the image features\n",
        "            image = cv.putText(image,'{}'.format(j),\n",
        "                              (np.int32(points[j][0]+15),np.int32(points[j][1]+10)),\n",
        "                              cv.FONT_HERSHEY_SIMPLEX, 16, (0,0,0), 4)\n",
        "\n",
        "        labelled_points.append(image)\n",
        "\n",
        "    # Display a sample of images\n",
        "    after = image_grid(labelled_points[:4], rows=2, cols=2, rgb=True, show_axes=False)\n",
        "\n",
        "    # Find the homography matrix for each image\n",
        "    homography_matrices = {}\n",
        "    matches_mask = {}\n",
        "\n",
        "    printing.options['dformat'] = '%.3f'\n",
        "    printing.options['width'] = -1\n",
        "\n",
        "    for idx, (path, _, points) in enumerate(raw_images):\n",
        "        h, mask = cv.findHomography(np.array(ref_points), np.array(points), cv.RANSAC, 5.0)\n",
        "\n",
        "        print(f\"H({idx}) = \")\n",
        "        print(matrix(h))\n",
        "        homography_matrices[str(path)] = h.tolist()\n",
        "        matches_mask[str(path)] = mask.ravel().tolist()\n",
        "\n",
        "    with open(\"matrices.json\", \"w+\") as f:\n",
        "      f.write(json.dumps({\n",
        "          \"homography\": homography_matrices,\n",
        "          \"matches\": matches_mask\n",
        "      }))\n",
        "\n",
        "    return [before, after]\n",
        "\n",
        "  @staticmethod\n",
        "  def load_matrices():\n",
        "    with open(\"matrices.json\", \"r\") as f:\n",
        "      data = json.load(f)\n",
        "\n",
        "    data = {\n",
        "        \"homography\": {\n",
        "            k: np.array(v) for k, v in data[\"homography\"].items()\n",
        "        },\n",
        "        \"matches\": {\n",
        "            k: np.array(v) for k, v in data[\"matches\"].items()\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return data[\"homography\"], data[\"matches\"]\n",
        "\n",
        "  @staticmethod\n",
        "  def load_calibration():\n",
        "    with open(\"calibration.json\", \"r\") as f:\n",
        "      data = json.load(f)\n",
        "\n",
        "    return np.array(data[\"K\"]), np.array(data[\"D\"]), np.array([data[\"width\"], data[\"height\"]])\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_from_homography(homography, inverse_intrinsic_camera_matrix):\n",
        "    \"\"\"\n",
        "    extractExtrinsicParametersFromHomography factorizes the homograpgy transformation to extract the camera pose,\n",
        "                                              i.e., rotation matrix and translation vector.\n",
        "\n",
        "    Input arguments:\n",
        "    ------------------\n",
        "        homography:    3x3 homography matrix\n",
        "        inverse_intrinsic_camera_matrix: 3x3 intrinsics matrix\n",
        "\n",
        "    return:\n",
        "    -------\n",
        "        Omega: 3x3 Rotation matrix,\n",
        "        tau:   3x1 translation vector\n",
        "    \"\"\"\n",
        "\n",
        "    # # Use openCV to estimate the camera's position and orientation\n",
        "    # _, rotation, translation, _ = cv.decomposeHomographyMat(\n",
        "    #     homography, camera_matrix)\n",
        "\n",
        "    # # Add the rotation matrix and translation vector to the list of camera poses\n",
        "    # camera_rotations.append(rotation)\n",
        "    # camera_translations.append(translation)\n",
        "\n",
        "    # Multiply the homography matrix by the inverse intrinsic camera matrix to eliminiate the effect\n",
        "    # of the camera's intrinsic parameters\n",
        "    homography_extrinsic = np.dot(inverse_intrinsic_camera_matrix, homography)\n",
        "\n",
        "    # Estimate the first two columns of the rotation matrix by computing the SVD of the first two\n",
        "    # columns of the homography matrix\n",
        "    U, L, Vt = np.linalg.svd(homography_extrinsic[:, 0:2])\n",
        "    new_L = np.array([[1, 0], [0, 1], [0, 0]])\n",
        "    rotation_matrix = U @ new_L @ Vt\n",
        "\n",
        "    # Estimate the third column of the rotation matrix by taking the cross product of the first two\n",
        "    # columns\n",
        "    third_column = np.cross(rotation_matrix[:, 0], rotation_matrix[:, 1])\n",
        "\n",
        "\n",
        "    rotation_matrix = np.c_[rotation_matrix, third_column]\n",
        "\n",
        "    # Verify that the rotation matrix is positive by checking its determinant\n",
        "    if np.linalg.det(rotation_matrix) < 0:\n",
        "        rotation_matrix[:, 2] *= -1\n",
        "\n",
        "    # Estimate the scaling factor by taking the average of the scaling factors between the original\n",
        "    # extrinsic homography matrix and the first two columns of the rotation matrix\n",
        "    scaling_factor = np.sum(homography_extrinsic[:, 0:2] / rotation_matrix[:, 0:2]) / 6\n",
        "\n",
        "    # Estimate the translation vector by dividing the third column of the extrinsic homography\n",
        "    # matrix by the scaling factor\n",
        "    translation = homography_extrinsic[:, 2] / scaling_factor\n",
        "\n",
        "    return rotation_matrix, translation\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_from_homography_cv(object_points, image_points, intrinsic_camera_matrix, dist_coeffs=None):\n",
        "    \"\"\"\n",
        "    Estimate pose from 3D-2D correspondences using solvePnP.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    object_points : np.ndarray (Nx3)\n",
        "        Known 3D points in world coordinates\n",
        "    image_points : np.ndarray (Nx2)\n",
        "        Corresponding 2D points in image plane\n",
        "    intrinsic_camera_matrix : np.ndarray (3x3)\n",
        "        Camera intrinsic matrix\n",
        "    dist_coeffs : np.ndarray (optional)\n",
        "        Distortion coefficients\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    rotation_matrix : np.ndarray (3x3)\n",
        "    translation_vector : np.ndarray (3x1)\n",
        "    \"\"\"\n",
        "\n",
        "    if object_points.shape[0] != image_points.shape[0]:\n",
        "        raise ValueError(\"object_points and image_points must have the same number of points\")\n",
        "\n",
        "    if object_points.shape[0] < 4:\n",
        "        raise ValueError(\"At least 4 correspondences are required for solvePnP\")\n",
        "\n",
        "\n",
        "    success, rvec, tvec = cv.solvePnP(\n",
        "        object_points,\n",
        "        image_points,\n",
        "        intrinsic_camera_matrix,\n",
        "        dist_coeffs if dist_coeffs is not None else np.zeros((4, 1)),\n",
        "        flags=0\n",
        "    )\n",
        "\n",
        "    if not success:\n",
        "        raise RuntimeError(\"solvePnP failed to find a valid pose\")\n",
        "\n",
        "    rotation_matrix, _ = cv.Rodrigues(rvec)\n",
        "    return rotation_matrix, tvec\n",
        "\n",
        "  @staticmethod\n",
        "  def plot_camera(\n",
        "      rotation: np.ndarray, translation: np.ndarray, intrinsic_matrix: np.ndarray, dimensions: np.ndarray\n",
        "  ):\n",
        "      virtual_image_distance = 0.1\n",
        "\n",
        "      # This is the camera coordinate frame\n",
        "      # Camera pose, i.e., the matrix [R t] of extrinsic parameters\n",
        "      Rt = np.block([rotation.T, -rotation.T @ translation.reshape((3,1))])\n",
        "\n",
        "      # Convert Rt from 3x4 to a 4x4 transformation matrix\n",
        "      Rt = np.vstack([Rt, [0, 0, 0, 1]])\n",
        "\n",
        "      print(matrix(Rt))\n",
        "\n",
        "      ax = pt.plot_transform(\n",
        "          A2B=Rt,\n",
        "          s=2\n",
        "      )\n",
        "\n",
        "      pc.plot_camera(\n",
        "          ax,\n",
        "          cam2world=Rt,\n",
        "          M=intrinsic_matrix,\n",
        "          sensor_size=dimensions,\n",
        "          virtual_image_distance=virtual_image_distance,\n",
        "      )\n",
        "\n",
        "      return ax\n",
        "\n",
        "  @staticmethod\n",
        "  def draw_axes(\n",
        "      img: np.ndarray,\n",
        "      rotation: np.ndarray,\n",
        "      translation: np.ndarray,\n",
        "      mtx: np.ndarray,\n",
        "      dist: np.ndarray\n",
        "  ):\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(img)\n",
        "\n",
        "    scale_factor = 6\n",
        "    W = scale_factor * np.array(\n",
        "        [[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], dtype=np.float64\n",
        "    )\n",
        "\n",
        "    rvec = cv.Rodrigues(rotation)[0]\n",
        "    tvec = translation.reshape(3, 1)\n",
        "\n",
        "    print(f\"W = \\n{W}\\n\")\n",
        "\n",
        "    image_axes, jac = cv.projectPoints(W, rvec, tvec, mtx, dist)\n",
        "    image_axes = image_axes.squeeze().T\n",
        "    print(f\"Projected image points = \\n{image_axes}\\n\")\n",
        "\n",
        "    Utils.draw_coordinate_frame(image_axes, img)\n",
        "\n",
        "    return fig\n",
        "\n",
        "  @staticmethod\n",
        "  def run_homography_pose():\n",
        "    homography, matches = Pose.load_matrices()\n",
        "    mtx, dist, dimensions = Pose.load_calibration()\n",
        "\n",
        "    # Calculate the inverse of the intrinsic camera matrix\n",
        "    inv_mtx = np.linalg.inv(mtx)\n",
        "\n",
        "    camera_rotations = []\n",
        "    camera_translations = []\n",
        "\n",
        "    axes = []\n",
        "\n",
        "    for idx, (path, homography) in enumerate(homography.items()):\n",
        "        # Extract extrinsic parameters from homography\n",
        "        rotation_matrix, translation = Pose.extract_from_homography(homography, inv_mtx)\n",
        "\n",
        "        print(rotation_matrix, translation)\n",
        "\n",
        "        if idx < 4:\n",
        "          axes.append(Pose.draw_axes(\n",
        "              cv.imread(path),\n",
        "              rotation_matrix,\n",
        "              translation,\n",
        "              mtx,\n",
        "              dist\n",
        "          ))\n",
        "\n",
        "        # Add the rotation matrix and translation vector to the list of camera poses\n",
        "        camera_rotations.append(rotation_matrix)\n",
        "        camera_translations.append(translation)\n",
        "\n",
        "    # Reference frame\n",
        "    camera_rotations.append(np.eye(3))\n",
        "    camera_translations.append(np.array([0, 0, 0]))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = None\n",
        "\n",
        "    cam2world = pt.transform_from_pq([0, 0, 0, 0, 0, 0, 0])\n",
        "    pt.plot_transform(\n",
        "        ax,\n",
        "        A2B=cam2world,\n",
        "        s=3,\n",
        "        # name=\"World\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Print the camera poses\n",
        "    for i, (rotation, translation) in enumerate(zip(camera_rotations, camera_translations)):\n",
        "        ax = Pose.plot_camera(rotation, translation, mtx, dimensions)\n",
        "\n",
        "    if ax is not None:\n",
        "      ax.view_init(30, 70)\n",
        "      ax.set_xlim(-100, 100)\n",
        "      ax.set_ylim(-100, 100)\n",
        "      ax.set_zlim(-100, 100)\n",
        "\n",
        "    return [fig, *axes]\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def run_decompose_homography_pose():\n",
        "      # Load saved homographies + calibration\n",
        "      homography, matches = Pose.load_matrices()\n",
        "      mtx, dist, dimensions = Pose.load_calibration()\n",
        "\n",
        "      camera_rotations = []\n",
        "      camera_translations = []\n",
        "\n",
        "      axes = []\n",
        "\n",
        "      ref_points = json.loads(open(\"ref_points.json\", \"r\").read())\n",
        "      ref_points = np.array([[*p[0], 0] for p in ref_points])\n",
        "      print(ref_points)\n",
        "\n",
        "      # Go through each image's homography\n",
        "      for idx, (path, H) in enumerate(homography.items()):\n",
        "          image = cv.imread(path)\n",
        "          points = np.array(json.loads(open(path.replace(\".jpg\", \".json\"), \"r\").read()), dtype=np.float32)\n",
        "          print(points)\n",
        "          # Calculate the inverse of the intrinsic camera matrix\n",
        "          # Extract extrinsic parameters from homography\n",
        "          rotation_matrix, translation = Pose.extract_from_homography_cv(ref_points, points, mtx, dist)\n",
        "\n",
        "          axes.append(Pose.draw_axes(\n",
        "              image,\n",
        "              rotation_matrix,\n",
        "              translation,\n",
        "              mtx,\n",
        "              dist\n",
        "          ))\n",
        "\n",
        "          # Add the rotation matrix and translation vector to the list of camera poses\n",
        "          camera_rotations.append(rotation_matrix)\n",
        "          camera_translations.append(translation)\n",
        "\n",
        "      # Add reference world frame\n",
        "      camera_rotations.append(np.eye(3))\n",
        "      camera_translations.append(np.array([0, 0, 0]))\n",
        "\n",
        "      # Create a new 3D figure for all cameras\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(111, projection=\"3d\")\n",
        "\n",
        "      # Plot world frame\n",
        "      cam2world = pt.transform_from_pq([0, 0, 0, 0, 0, 0, 0])\n",
        "      pt.plot_transform(ax, A2B=cam2world, s=3)\n",
        "\n",
        "      # Plot each estimated camera pose\n",
        "      for R, t in zip(camera_rotations, camera_translations):\n",
        "          ax = Pose.plot_camera(R, t, mtx, dimensions)\n",
        "\n",
        "      # Adjust visualization\n",
        "      ax.view_init(30, 70)\n",
        "      ax.set_xlim(-100, 100)\n",
        "      ax.set_ylim(-100, 100)\n",
        "      ax.set_zlim(-100, 100)\n",
        "\n",
        "      return [fig, *axes]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UI Tabs"
      ],
      "metadata": {
        "id": "jZjBejmHzrbh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mibCRFn9MnV"
      },
      "outputs": [],
      "source": [
        "class CalibrationUI:\n",
        "  @staticmethod\n",
        "  def save_images(images):\n",
        "    for image in images:\n",
        "      destination = calibration_images_dir / Path(image.name).name\n",
        "      with open(image.name, \"rb\") as src, open(destination, \"wb\") as dst:\n",
        "        dst.write(src.read())\n",
        "    return \"Upload Successful!\"\n",
        "\n",
        "  @staticmethod\n",
        "  def calibration_tab():\n",
        "    with gradio.Tab(\"Calibration / Upload\"):\n",
        "      gradio.Markdown(\"### Calibration UI\")\n",
        "      upload = gradio.Files(file_types=[\".jpeg\", \".jpg\"])\n",
        "      upload_button = gradio.Button(\"Upload Images\")\n",
        "      upload_output = gradio.Textbox(label=\"Upload status\")\n",
        "\n",
        "      calibrate_button = gradio.Button(\"Run Calibration\")\n",
        "\n",
        "      upload_button.click(fn=CalibrationUI.save_images, inputs=upload, outputs=upload_output)\n",
        "      calibrate_button.click(fn=Calibration.run, outputs=[gradio.Text()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTZcoZTQ9b9b"
      },
      "outputs": [],
      "source": [
        "class PoseEstimationUI:\n",
        "  @staticmethod\n",
        "  def save_images(images):\n",
        "    for image in images:\n",
        "      destination = planar_images_dir / Path(image.name).name\n",
        "      with open(image.name, \"rb\") as src, open(destination, \"wb\") as dst:\n",
        "        dst.write(src.read())\n",
        "\n",
        "    return \"Upload Successful!\"\n",
        "\n",
        "  @staticmethod\n",
        "  def picker_tab():\n",
        "    # --- Single-image point picker using notebook variable `my_image` ---\n",
        "    import gradio as gr\n",
        "    from PIL import Image, ImageDraw, ImageFont\n",
        "    import numpy as np\n",
        "    import threading, json, os, io\n",
        "    font = ImageFont.load_default(size=48)\n",
        "    # Data\n",
        "    points_store = []\n",
        "    app = None\n",
        "    SELECTED_POINTS = None\n",
        "\n",
        "    def _to_pil_from_numpy(arr: np.ndarray) -> Image.Image:\n",
        "        arr = np.asarray(arr)\n",
        "        # channel-first -> channel-last\n",
        "        if arr.ndim == 3 and arr.shape[0] in (1,3,4) and arr.shape[-1] not in (1,3,4):\n",
        "            arr = np.transpose(arr, (1,2,0))\n",
        "        if np.issubdtype(arr.dtype, np.floating):\n",
        "            # scale floats in [0,1] to [0,255]\n",
        "            arr = (np.clip(arr, 0.0, 1.0) * 255.0).round().astype(np.uint8)\n",
        "        elif arr.dtype != np.uint8:\n",
        "            arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
        "        # Choose mode\n",
        "        if arr.ndim == 2:\n",
        "            return Image.fromarray(arr, mode=\"L\")\n",
        "        if arr.ndim == 3 and arr.shape[2] == 3:\n",
        "            return Image.fromarray(arr, mode=\"RGB\")\n",
        "        if arr.ndim == 3 and arr.shape[2] == 4:\n",
        "            return Image.fromarray(arr, mode=\"RGBA\")\n",
        "        if arr.ndim == 3 and arr.shape[2] == 1:\n",
        "            return Image.fromarray(arr[:,:,0], mode=\"L\")\n",
        "        raise ValueError(f\"Unsupported array shape: {arr.shape}\")\n",
        "\n",
        "    def _to_pil(img):\n",
        "        if isinstance(img, Image.Image):\n",
        "            return img\n",
        "        if isinstance(img, np.ndarray):\n",
        "            return _to_pil_from_numpy(img)\n",
        "        raise gr.Error(\"Set `my_image` to a PIL image or NumPy array before launching.\")\n",
        "\n",
        "    def _draw_points(base_img: Image.Image, pts, radius=64):\n",
        "        img = base_img.copy().convert(\"RGB\")\n",
        "\n",
        "        d = ImageDraw.Draw(img)\n",
        "        for (idx, (x, y)) in enumerate(pts):\n",
        "            d.ellipse([x-radius, y-radius, x+radius, y+radius], fill=(255,0,0))\n",
        "            d.text((x,y), str(idx), font=font, fill=(0,0,0))\n",
        "        return img\n",
        "\n",
        "    # Prepare base image from notebook variable\n",
        "    # if 'my_image' not in globals():\n",
        "        # raise RuntimeError(\"Please define `my_image` (PIL image or NumPy array) before running this cell.\")\n",
        "    # base_pil = _to_pil(globals()['my_image'])\n",
        "\n",
        "\n",
        "    def _refresh_numpy():\n",
        "        \"\"\"Return current preview (base + points) as numpy for Gradio.\"\"\"\n",
        "        return np.array(_draw_points(PoseEstimationUI.selected_image, points_store))\n",
        "\n",
        "    def on_click(evt: gr.SelectData):\n",
        "        # Get coordinates robustly\n",
        "        x = y = None\n",
        "        if hasattr(evt, \"index\") and evt.index is not None:\n",
        "            try: x, y = evt.index\n",
        "            except: pass\n",
        "        if (x is None or y is None) and hasattr(evt, \"x\") and hasattr(evt, \"y\"):\n",
        "            x, y = evt.x, evt.y\n",
        "        if x is None or y is None:\n",
        "            return gr.update(), json.dumps(points_store)\n",
        "\n",
        "        # Clamp to image bounds\n",
        "        w, h = PoseEstimationUI.selected_image.size\n",
        "        x = int(max(0, min(w-1, x)))\n",
        "        y = int(max(0, min(h-1, y)))\n",
        "\n",
        "        points_store.append([x, y])\n",
        "        return _refresh_numpy(), json.dumps(points_store)\n",
        "\n",
        "    def undo_last():\n",
        "        if points_store:\n",
        "            points_store.pop()\n",
        "        return _refresh_numpy(), json.dumps(points_store)\n",
        "\n",
        "    def clear_points():\n",
        "        points_store.clear()\n",
        "\n",
        "        PoseEstimationUI.selected_image = None\n",
        "        PoseEstimationUI.selected_image_path = None\n",
        "\n",
        "        return [\n",
        "            gr.update(visible=False), # Image\n",
        "            gr.update(visible=True),  # Upload Area\n",
        "            gr.update(visible=True),  # Upload Button\n",
        "            \"\"                        # Points text\n",
        "        ]\n",
        "\n",
        "    def done_btn_click():\n",
        "        \"\"\"Save to notebook var `selected_points` and close the app.\"\"\"\n",
        "\n",
        "        name = PoseEstimationUI.selected_image_path.name.split(\".\")[0]\n",
        "        destination = planar_images_dir / f\"{name}.json\"\n",
        "\n",
        "        with open(destination, \"w+\") as f:\n",
        "          f.write(json.dumps(points_store))\n",
        "\n",
        "        return f\"✅ Saved {len(points_store)}\"\n",
        "\n",
        "    def save_image(file):\n",
        "      destination = planar_images_dir / Path(file.name).name\n",
        "      with open(file.name, \"rb\") as src, open(destination, \"wb\") as dst:\n",
        "        dst.write(src.read())\n",
        "\n",
        "      PoseEstimationUI.selected_image_path = destination\n",
        "      PoseEstimationUI.selected_image = _to_pil_from_numpy(cv.imread(destination))\n",
        "\n",
        "      return [\n",
        "        gr.update(visible=True, value=_refresh_numpy()),  # Image\n",
        "        gr.update(visible=False, value=None),             # Upload Area\n",
        "        gr.update(visible=False),                         # Upload Button\n",
        "      ]\n",
        "\n",
        "    #with gr.Tab(\"Pose Estimation (Point Picker)\"):\n",
        "    with gr.Blocks(title=\"Pose Estimation (Point Picker)\") as demo:\n",
        "        gr.Markdown(\"**Click on the image to add points.** Use Undo / Clear as needed, then press **Done**.\")\n",
        "\n",
        "        img = gr.Image(\n",
        "          label=\"Image (click to add points)\",\n",
        "          type=\"numpy\", interactive=True, sources=[],\n",
        "          visible=False\n",
        "        )\n",
        "\n",
        "        upload = gr.File(file_types=[\".jpg\"])\n",
        "        upload_button = gr.Button(\"Upload Images\")\n",
        "\n",
        "\n",
        "        with gr.Row():\n",
        "            undo_btn = gr.Button(\"↩️ Undo\")\n",
        "            clear_btn = gr.Button(\"🧹 Clear\")\n",
        "            done_btn = gr.Button(\"✅ Done\", variant=\"primary\")\n",
        "        pts_text = gr.Textbox(label=\"Points (JSON)\", value=\"[]\", interactive=False)\n",
        "        status = gr.Markdown(\"\")\n",
        "\n",
        "        # One image used for both input and output\n",
        "        img.select(on_click, inputs=None, outputs=[img, pts_text])\n",
        "        upload_button.click(save_image, inputs=[upload], outputs=[img, upload, upload_button])\n",
        "        undo_btn.click(lambda: undo_last(), outputs=[img, pts_text])\n",
        "        clear_btn.click(clear_points, outputs=[img, upload, upload_button, pts_text])\n",
        "        done_btn.click(done_btn_click, outputs=[status])\n",
        "\n",
        "        app = demo.launch(inline=True, prevent_thread_lock=True, debug=True)\n",
        "        return app\n",
        "\n",
        "class HomographyUI:\n",
        "  @staticmethod\n",
        "  def homography_tab():\n",
        "    with gradio.Tab(\"Homography Poses\"):\n",
        "      homography_get_button = gradio.Button(\"Calculate Homography Matrices\")\n",
        "      homography_get_button.click(fn=Pose.run_get_homography, outputs=[gradio.Plot() for i in range(2)])\n",
        "\n",
        "      gradio.Markdown(\"### Homography Poses\")\n",
        "\n",
        "      homography_pose_button = gradio.Button(\"Run Homography -> Pose\")\n",
        "      homography_pose_button.click(fn=Pose.run_homography_pose, outputs=[gradio.Plot() for i in range(5)])\n",
        "\n",
        "      cv_pose_button = gradio.Button(\"Run OpenCV Pose\")\n",
        "      cv_pose_button.click(fn=Pose.run_decompose_homography_pose, outputs=[gradio.Plot() for i in range(5)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSgQ_XR-3K1a"
      },
      "outputs": [],
      "source": [
        "class CentralUI:\n",
        "  @staticmethod\n",
        "  def run():\n",
        "    with gradio.Blocks(title=\"Camera Calibration & Pose Tool\") as ui:\n",
        "        with gradio.Tabs():\n",
        "            CalibrationUI.calibration_tab()\n",
        "            #PoseEstimationUI.picker_tab()\n",
        "            HomographyUI.homography_tab()\n",
        "\n",
        "    ui.launch(share=False, inline=True, prevent_thread_lock=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Driver Code (Picker and Central UI App)"
      ],
      "metadata": {
        "id": "DbNaGhxFzyJh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3LaFsI6k2BX"
      },
      "outputs": [],
      "source": [
        "PoseEstimationUI.picker_tab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oyEmxYh0IfT3"
      },
      "outputs": [],
      "source": [
        "CentralUI.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}