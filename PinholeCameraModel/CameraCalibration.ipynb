{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielx1611/ComputerVisionAssignments/blob/main/PinholeCameraModel/CameraCalibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Camera Calibration with Gradio UI"
      ],
      "metadata": {
        "id": "d56RU_Upyfdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gradio numpy opencv-python matplotlib pytransform3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yyfI1HbhycE",
        "outputId": "22db037c-73fc-4a2e-ffae-f4fc6d3c292a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting pytransform3d\n",
            "  Downloading pytransform3d-3.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytransform3d) (1.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from pytransform3d) (5.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.8)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading pytransform3d-3.14.2-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.7/164.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytransform3d\n",
            "Successfully installed pytransform3d-3.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "import time\n",
        "import gradio\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pytransform3d.camera as pc\n",
        "import pytransform3d.transformations as pt\n",
        "import io\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "def cv2_imshow(img):\n",
        "    cv.imshow(\"img\", img)\n",
        "    time.sleep(1)\n",
        "    cv.destroyAllWindows()\n",
        "\n",
        "CONTENT_DIR = Path(\".\")\n",
        "\n",
        "try:\n",
        "    import google.colab.patches as patches\n",
        "    print(\"in collab\")\n",
        "    cv2_imshow = patches.cv2_imshow\n",
        "    CONTENT_DIR = Path(\"/content\")\n",
        "\n",
        "    if not Path(\"ComputerVisionAssignments\").exists():\n",
        "      !git clone https://github.com/danielx1611/ComputerVisionAssignments\n",
        "\n",
        "    # Move test files to the Colab local directory (i.e., /content/)\n",
        "    if not Path(\"images\").exists():\n",
        "      !mkdir images\n",
        "    !cp -r ComputerVisionAssignments/PinholeCameraModel/chess_jpg/* ./images\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "r9xUxJuWPGLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166da8e8-4244-488b-a61a-c6b2d213c0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in collab\n",
            "Cloning into 'ComputerVisionAssignments'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 87 (delta 0), reused 0 (delta 0), pack-reused 78 (from 2)\u001b[K\n",
            "Receiving objects: 100% (87/87), 48.68 MiB | 19.46 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Camera Calibration"
      ],
      "metadata": {
        "id": "t8QVS0J8yXBW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqG8IlmNxnUS"
      },
      "outputs": [],
      "source": [
        "image_dir = CONTENT_DIR / \"images\"\n",
        "output_dir = CONTENT_DIR / \"output\"\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "images = list(image_dir.glob(\"*.jpeg\")) + list(image_dir.glob(\"*.jpg\"))\n",
        "\n",
        "\n",
        "class Calibration:\n",
        "    @staticmethod\n",
        "    def run():\n",
        "        # termination criteria\n",
        "        criteria = (\n",
        "            cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER,\n",
        "            30,\n",
        "            0.001,\n",
        "        )  # 30: max_iter , 0.001 : accuracy\n",
        "\n",
        "        # prepare object points, like (0,0,0), (1,0,0), ..., (6,5,0)\n",
        "        objp = np.zeros((9 * 6, 3), np.float32)  #\n",
        "        objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(\n",
        "            -1, 2\n",
        "        )  # reshaped to [42,2] only take X and Y\n",
        "\n",
        "\n",
        "        calibration_data = {}\n",
        "\n",
        "        CHECKERBOARD_SIZE = (9, 6)\n",
        "\n",
        "        for fname in images:\n",
        "            # Arrays to store object points and image points from all the images.\n",
        "            objpoints: list[cv.typing.MatLike] = []  # 3d point in real world space [X,Y,Z]\n",
        "            imgpoints: list[cv.typing.MatLike] = []  # 2d points in image plane. [X,Y]\n",
        "\n",
        "            print(fname)\n",
        "            img = cv.imread(str(fname))\n",
        "\n",
        "            if img is None:\n",
        "                print(\"Invalid image\")\n",
        "                continue\n",
        "\n",
        "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Find the chess board corners\n",
        "            ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD_SIZE, None)\n",
        "\n",
        "            # If found, add object points, image points (after refining them)\n",
        "            if ret == True:\n",
        "                objpoints.append(objp)\n",
        "\n",
        "                corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
        "                imgpoints.append(corners2)\n",
        "\n",
        "                # Draw and display the corners\n",
        "                cv.drawChessboardCorners(img, CHECKERBOARD_SIZE, corners2, ret)\n",
        "                # cv.imshow(\"img\", img)\n",
        "                # cv.waitKey(500)\n",
        "\n",
        "                cv.imwrite(str(CONTENT_DIR / \"output\" / (fname.name + \"_corners.png\")), img)\n",
        "\n",
        "                # Calibration Part\n",
        "                ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)  # type: ignore\n",
        "\n",
        "                img = cv.imread(str(fname))\n",
        "\n",
        "                if img is None:\n",
        "                    continue\n",
        "\n",
        "                h, w = img.shape[:2]\n",
        "                # newcameramtx, roi = cv.getOptimalNewCameraMatrix(\n",
        "                #     mtx, dist, (w, h), 0, (w, h)\n",
        "                # )\n",
        "\n",
        "                # dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
        "\n",
        "                # # crop the image\n",
        "                # x, y, w, h = roi\n",
        "                # dst = dst[y:y+h, x:x+w]\n",
        "#\n",
        "                # cv.imwrite(str(CONTENT_DIR / \"output\" / (fname.name + \"_undistort.png\")), dst)\n",
        "\n",
        "                # Save results into calibration.json\n",
        "                calibration_data[str(fname)] = (\n",
        "                    {\n",
        "                        \"K\": mtx.tolist(),  # Intrinsic matrix\n",
        "                        \"D\": dist.tolist(),  # Distortion coefficients\n",
        "                        \"R\": [\n",
        "                            cv.Rodrigues(r)[0].tolist() for r in rvecs\n",
        "                        ],  # Convert rvec to rotation matrix\n",
        "                        \"t\": [t.tolist() for t in tvecs],  # Translation vectors\n",
        "                        \"width\": w,\n",
        "                        \"height\": h,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                mean_error = 0\n",
        "                for i in range(len(objpoints)):\n",
        "                    imgpoints2, _ = cv.projectPoints(\n",
        "                        objpoints[i], rvecs[i], tvecs[i], mtx, dist\n",
        "                    )\n",
        "                    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2) / len(imgpoints2)\n",
        "                    mean_error += error\n",
        "\n",
        "                print(\"total error: {}\".format(mean_error / len(objpoints)))\n",
        "\n",
        "        with open(\"calibration.json\", \"w\") as f:\n",
        "            json.dump(calibration_data, f, indent=2)\n",
        "\n",
        "        return \"Calibration successful\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "qeWtU7IbO2cZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "y2WZMhu4PRDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Utils:\n",
        "    @staticmethod\n",
        "    def project_points(W: np.ndarray,\n",
        "                       Lambda: np.ndarray,\n",
        "                       Rt: np.ndarray) -> np.ndarray:\n",
        "        \"\"\" Helper function to project 3D points to 2D image plane\"\"\"\n",
        "\n",
        "        # Convert points to homogeneous coordinates\n",
        "        W_tilde = np.vstack((W, np.ones((1, W.shape[1]))))\n",
        "\n",
        "        print(f\"W_tilde = \\n{W_tilde}\\n\")\n",
        "\n",
        "        # Calculate perspective projection in homogeneous coordinates\n",
        "        X_tilde = Lambda @ Rt @ W_tilde\n",
        "\n",
        "        print(f\"X_tilde =  \\n{X_tilde}\\n\")\n",
        "\n",
        "        # Apply perspective division to convert coordinates from homogeneous to Cartesian\n",
        "        X_tilde /= X_tilde[2,:]\n",
        "        # Convert coordinates from homogeneous to Cartesian\n",
        "        X = X_tilde[0:2,:]\n",
        "\n",
        "        return X\n",
        "\n",
        "    @staticmethod\n",
        "    def draw_coordinate_frame(image_points, img):\n",
        "        x0, y0 = image_points[:,0].astype(int)\n",
        "        cv.circle(img, (x0, y0), 9, (0, 0, 0), -1)\n",
        "\n",
        "        x1, y1 = image_points[:,1].astype(int)\n",
        "        img = cv.arrowedLine(img, (x0, y0), (x1, y1), (255, 0, 0), 5)\n",
        "\n",
        "        x2, y2 = image_points[:,2].astype(int)\n",
        "        img = cv.arrowedLine(img, (x0, y0), (x2, y2), (0, 255, 0), 5)\n",
        "\n",
        "        x3, y3 = image_points[:,3].astype(int)\n",
        "        img = cv.arrowedLine(img, (x0, y0), (x3, y3), (0, 0, 255), 5)\n",
        "\n",
        "        plt.imshow(img)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_Lambda(phi_x, phi_y, skew, delta_x, delta_y):\n",
        "        \"\"\" Build the intrinsic camera matrix Lambda \"\"\"\n",
        "        Lambda = np.array([[phi_x,  skew, delta_x],\n",
        "                           [    0, phi_y, delta_y],\n",
        "                           [    0,     0,       1]])\n",
        "        return Lambda\n",
        "\n",
        "    @staticmethod\n",
        "    def json_read(filename):\n",
        "        # Parses the json file\n",
        "        try:\n",
        "            with open(os.path.abspath(filename)) as f:\n",
        "                data = json.load(f)\n",
        "            return data\n",
        "        except:\n",
        "            raise ValueError(\"Unable to read JSON {}\".format(filename))"
      ],
      "metadata": {
        "id": "oj0cPd9PKzNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "KMa5UrByPUrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Visualization:\n",
        "    @staticmethod\n",
        "    def calibration_matrices(view: dict) -> tuple[np.ndarray, ...]:\n",
        "        # Get the calibration matrices\n",
        "        Lambda = np.array(view[\"K\"])  # Intrinsic params.\n",
        "        Omega = np.array(view[\"R\"])  # Rotation\n",
        "        tau = np.array(view[\"t\"])  # Translation\n",
        "        dist = np.array(view[\"D\"])  # Lens distortion\n",
        "\n",
        "        Lambda = Lambda.reshape(3, 3)\n",
        "        Omega = Omega.reshape(3, 3)\n",
        "        tau = tau.reshape(3, 1)\n",
        "\n",
        "        return (Lambda, Omega, tau, dist)\n",
        "\n",
        "    @staticmethod\n",
        "    def undistort(view: dict, img: cv.typing.MatLike):\n",
        "        Lambda, Omega, tau, dist = Visualization.calibration_matrices(view)\n",
        "\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(img)\n",
        "\n",
        "        scale_factor = 2\n",
        "        W = scale_factor * np.array(\n",
        "            [[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], dtype=np.float64\n",
        "        )\n",
        "\n",
        "        rvec = cv.Rodrigues(Omega)[0]\n",
        "        tvec = tau.reshape(3, 1)\n",
        "\n",
        "        print(f\"W = \\n{W}\\n\")\n",
        "\n",
        "        image_axes, jac = cv.projectPoints(W, rvec, tvec, Lambda, dist)\n",
        "        image_axes = image_axes.squeeze().T\n",
        "        print(f\"Projected image points = \\n{image_axes}\\n\")\n",
        "\n",
        "        Utils.draw_coordinate_frame(image_axes, img)\n",
        "\n",
        "        return fig\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_camera(\n",
        "        Lambda: np.ndarray, Omega: np.ndarray, tau: np.ndarray, dimensions: list[int]\n",
        "    ):\n",
        "        sensor_size = np.array(dimensions)\n",
        "        intrinsic_matrix = Lambda\n",
        "\n",
        "        virtual_image_distance = 0.1\n",
        "\n",
        "        # This is the camera coordinate frame\n",
        "        # Camera pose, i.e., the matrix [R t] of extrinsic parameters\n",
        "        Rt = np.block([Omega.T, -Omega.T @ tau])\n",
        "\n",
        "        # Convert Rt from 3x4 to a 4x4 transformation matrix\n",
        "        Rt = np.vstack([Rt, [0, 0, 0, 1]])\n",
        "\n",
        "        # Print camera extrinsic parameters\n",
        "\n",
        "        cam2world = Rt\n",
        "        ax = pt.plot_transform(\n",
        "            A2B=cam2world,\n",
        "            s=2,\n",
        "            # name=\"Camera\"\n",
        "        )\n",
        "\n",
        "        pc.plot_camera(\n",
        "            ax,\n",
        "            cam2world=cam2world,\n",
        "            M=intrinsic_matrix,\n",
        "            sensor_size=sensor_size,\n",
        "            virtual_image_distance=virtual_image_distance,\n",
        "        )\n",
        "\n",
        "\n",
        "        return ax\n",
        "\n",
        "    @staticmethod\n",
        "    def get_calibration_data():\n",
        "        with open(\"calibration.json\", \"r\") as f:\n",
        "            calibration_data: dict[str, dict] = json.loads(f.read())\n",
        "\n",
        "        return calibration_data\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_cameras():\n",
        "        calibration_data = Visualization.get_calibration_data()\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = None\n",
        "\n",
        "        for img in images:\n",
        "            view = calibration_data[str(img)]\n",
        "\n",
        "            img = cv.imread(str(images[0]))\n",
        "\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            Lambda, Omega, tau, _ = Visualization.calibration_matrices(view)\n",
        "\n",
        "            ax = Visualization.plot_camera(\n",
        "                Lambda,\n",
        "                Omega,\n",
        "                tau,\n",
        "                img.shape[:2]\n",
        "            )\n",
        "\n",
        "\n",
        "        cam2world = pt.transform_from_pq([0, 0, 0, 0, 0, 0, 0])\n",
        "        pt.plot_transform(\n",
        "            ax,\n",
        "            A2B=cam2world,\n",
        "            s=3,\n",
        "            # name=\"World\"\n",
        "        )\n",
        "\n",
        "        if ax is not None:\n",
        "          ax.view_init(30, 70)\n",
        "          ax.set_xlim(-32, 32)\n",
        "          ax.set_ylim(-32, 32)\n",
        "          ax.set_zlim(-32, 32)\n",
        "\n",
        "        return fig\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def show_world_axis():\n",
        "        calibration_data = Visualization.get_calibration_data()\n",
        "\n",
        "        bufs = []\n",
        "        for i, (img) in enumerate(images):\n",
        "            print(img)\n",
        "            if i >= 5:\n",
        "                break\n",
        "\n",
        "            view = calibration_data[str(img)]\n",
        "\n",
        "            img = cv.imread(str(CONTENT_DIR / \"output\" / (img.name + \"_corners.png\")))\n",
        "\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            bufs.append(Visualization.undistort(view, img))\n",
        "\n",
        "        return bufs\n",
        "\n",
        "    @staticmethod\n",
        "    def distort_preview():\n",
        "        normal = plt.figure()\n",
        "\n",
        "        img = cv.imread(str(images[0]))\n",
        "\n",
        "        if img is None:\n",
        "            raise Exception(\"Failed to read img\")\n",
        "\n",
        "        plt.imshow(img)\n",
        "\n",
        "        undistorted = plt.figure()\n",
        "\n",
        "        calibration_data = Visualization.get_calibration_data()\n",
        "\n",
        "        Lambda, _, _, dist = Visualization.calibration_matrices(calibration_data[str(images[0])])\n",
        "        img_corrected = cv.undistort(img, Lambda, dist)\n",
        "        plt.imshow(img_corrected)\n",
        "\n",
        "        return [normal, undistorted]\n",
        "\n",
        "    @staticmethod\n",
        "    def run():\n",
        "        camera = Visualization.plot_cameras()\n",
        "        axises = Visualization.show_world_axis()\n",
        "        distortion = Visualization.distort_preview()\n",
        "\n",
        "        return [camera, *axises, *distortion]"
      ],
      "metadata": {
        "id": "fKlJJLVrL07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio UI"
      ],
      "metadata": {
        "id": "zB3R4hGcyk2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class GradioUI:\n",
        "  @staticmethod\n",
        "  def save_images(images):\n",
        "    for image in images:\n",
        "      destination = image_dir / Path(image.name).name\n",
        "      with open(image.name, \"rb\") as src, open(destination, \"wb\") as dst:\n",
        "        dst.write(src.read())\n",
        "    return \"Upload Successful!\"\n",
        "\n",
        "  @staticmethod\n",
        "  def run():\n",
        "    with gradio.Blocks() as ui:\n",
        "      gradio.Markdown(\"### Calibration UI\")\n",
        "      upload = gradio.Files(file_types=[\".jpeg\", \".jpg\"])\n",
        "      upload_button = gradio.Button(\"Upload Images\")\n",
        "      upload_output = gradio.Textbox(label=\"Upload status\")\n",
        "\n",
        "      calibrate_button = gradio.Button(\"Run Calibration\")\n",
        "\n",
        "      visualize_button = gradio.Button(\"Visualize Results\")\n",
        "\n",
        "      upload_button.click(fn=GradioUI.save_images, inputs=upload, outputs=upload_output)\n",
        "      calibrate_button.click(fn=Calibration.run)\n",
        "      visualize_button.click(fn=Visualization.run, outputs=[gradio.Plot() for _ in range(8)])\n",
        "\n",
        "      ui.launch(share=False, inline=True)"
      ],
      "metadata": {
        "id": "NbNSuZUBylE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interact"
      ],
      "metadata": {
        "id": "6A5r6kxDPZax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GradioUI.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "EppybKeFPc2w",
        "outputId": "c0f0d931-3b22-4e1a-9d82-9d99753e3af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}